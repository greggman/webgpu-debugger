<!doctype html>

<html>

<head>
  <meta charset='utf-8'>
  <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
  <meta name='mobile-web-app-capable' content='yes'>
  <meta name='apple-mobile-web-app-capable' content='yes'>

  <title>WebGPU test</title>

  <style>
    html,
    body {
      height: 100%;
      margin: 0;
      background-color: #000066;
    }

    canvas {
      margin: 1em;
    }
  </style>
</head>

<body>
  <canvas></canvas>
  <script type="module">
    import '../dist/webgpu-debugger.js';
    import { mat4, vec3 } from 'https://cdn.jsdelivr.net/npm/gl-matrix@3.4.3/esm/index.js';;

    const depthFormat = "depth24plus-stencil8";
    const sampleCount = 4;

    const uniformBufferSize = 4 * 16; // 4x4 matrix

    const shaderSrc = `
        struct Uniforms {
          modelViewProjectionMatrix : mat4x4<f32>
        };
        @group(0) @binding(0) var<uniform> uniforms : Uniforms;

        @group(0) @binding(1) var img : texture_2d<f32>;
        @group(0) @binding(2) var imgSampler : sampler;

        struct VertexInput {
          @location(0) position : vec4<f32>,
          @location(1) color : vec4<f32>,
          @location(2) texCoord : vec2<f32>,
        };

        struct VertexOutput {
          @location(0) color : vec4<f32>,
          @location(1) texCoord : vec2<f32>,
          @builtin(position) position : vec4<f32>,
        };

        @vertex
        fn vertMain(input : VertexInput) -> VertexOutput {
          var output : VertexOutput;
          output.color = input.color;
          output.texCoord = input.texCoord;
          output.position = uniforms.modelViewProjectionMatrix * input.position;
          return output;
        }

        @fragment
        fn fragMain(input : VertexOutput) -> @location(0) vec4<f32> {
          return input.color * textureSample(img, imgSampler, input.texCoord);
        }
      `;

    const Cube = {
      layout: {
        arrayStride: 4 * 9, // Byte size of one cube vertex
        attributes: [{
          // position
          shaderLocation: 0,
          offset: 0,
          format: "float32x3"
        }, {
          // color
          shaderLocation: 1,
          offset: 4 * 3,
          format: "float32x4"
        },
        {
          // UV
          shaderLocation: 2,
          offset: 4 * 7,
          format: "float32x2"
        }]
      },
      vertexCount: 36,
      vertexArray: new Float32Array([
        // float3 position, float4 color, float2 uv,
        1, -1, 1, 1, 0, 1, 1, 1, 0,
        -1, -1, 1, 0, 0, 1, 1, 0, 0,
        -1, -1, -1, 0, 0, 0, 1, 0, 1,
        1, -1, -1, 1, 0, 0, 1, 1, 1,
        1, -1, 1, 1, 0, 1, 1, 1, 0,
        -1, -1, -1, 0, 0, 0, 1, 0, 1,

        1, 1, 1, 1, 1, 1, 1, 1, 0,
        1, -1, 1, 1, 0, 1, 1, 0, 0,
        1, -1, -1, 1, 0, 0, 1, 0, 1,
        1, 1, -1, 1, 1, 0, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 0,
        1, -1, -1, 1, 0, 0, 1, 0, 1,

        -1, 1, 1, 0, 1, 1, 1, 1, 0,
        1, 1, 1, 1, 1, 1, 1, 0, 0,
        1, 1, -1, 1, 1, 0, 1, 0, 1,
        -1, 1, -1, 0, 1, 0, 1, 1, 1,
        -1, 1, 1, 0, 1, 1, 1, 1, 0,
        1, 1, -1, 1, 1, 0, 1, 0, 1,

        -1, -1, 1, 0, 0, 1, 1, 1, 0,
        -1, 1, 1, 0, 1, 1, 1, 0, 0,
        -1, 1, -1, 0, 1, 0, 1, 0, 1,
        -1, -1, -1, 0, 0, 0, 1, 1, 1,
        -1, -1, 1, 0, 0, 1, 1, 1, 0,
        -1, 1, -1, 0, 1, 0, 1, 0, 1,

        1, 1, 1, 1, 1, 1, 1, 1, 0,
        -1, 1, 1, 0, 1, 1, 1, 0, 0,
        -1, -1, 1, 0, 0, 1, 1, 0, 1,
        1, -1, 1, 1, 0, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 0,
        -1, -1, 1, 0, 0, 1, 1, 0, 1,

        1, -1, -1, 1, 0, 0, 1, 1, 0,
        -1, -1, -1, 0, 0, 0, 1, 0, 0,
        -1, 1, -1, 0, 1, 0, 1, 0, 1,
        1, 1, -1, 1, 1, 0, 1, 1, 1,
        1, -1, -1, 1, 0, 0, 1, 1, 0,
        -1, 1, -1, 0, 1, 0, 1, 0, 1,
      ])
    };

    let canvas;
    let context;
    let adapter;
    let device;
    let queue;
    let contextFormat;
    let vertexBuffer;
    let colorTexture;
    let depthTexture;
    let pipeline;
    let renderPassDescriptor;
    let uniformBuffer;
    let uniformBindGroup;

    let viewMatrix = mat4.create();
    let projectionMatrix = mat4.create();
    let modelViewProjectionMatrix = mat4.create();

    async function initWebGPU() {
      adapter = await navigator.gpu.requestAdapter();
      device = await adapter.requestDevice();

      canvas = document.querySelector('canvas');
      canvas.width = canvas.height = 400;
      context = canvas.getContext('webgpu');
      contextFormat = 'bgra8unorm';
      if ('getPreferredFormat' in context) {
        contextFormat = navigator.gpu.getPreferredCanvasFormat();
      }
      context.configure({
        device,
        format: contextFormat,
        usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC,
        compositingAlphaMode: 'opaque'
      });

      // Quick patch for Firefox/Chrome compat difference
      if (!device.queue) {
        device.queue = device.defaultQueue;
      }

      vertexBuffer = device.createBuffer({
        label: 'Cube Vertex Buffer',
        size: Cube.vertexArray.byteLength,
        usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
      });
      device.queue.writeBuffer(vertexBuffer, 0, Cube.vertexArray.buffer);

      const shaderModule = device.createShaderModule({
        label: 'Cube Shader',
        code: shaderSrc
      });

      pipeline = device.createRenderPipeline({
        label: 'Cube Render Pipeline',
        layout: 'auto',
        vertex: {
          module: shaderModule,
          entryPoint: 'vertMain',
          buffers: [Cube.layout],
        },
        fragment: {
          module: shaderModule,
          entryPoint: 'fragMain',
          targets: [{
            format: contextFormat,
          }],
        },

        primitive: {
          topology: 'triangle-list',
          cullMode: 'none',
        },
        depthStencil: {
          format: depthFormat,
          depthWriteEnabled: true,
          depthCompare: 'less',
          stencilFront: {
            passOp: 'increment-wrap',
          },
          stencilBack: {
            passOp: 'increment-wrap',
          }
        },
        multisample: { count: sampleCount, },
      });

      renderPassDescriptor = {
        colorAttachments: [{
          // view is acquired and set in render loop.
          view: undefined,
          resolveTarget: undefined,
          loadOp: 'clear',
          storeOp: 'store',
        }],
        depthStencilAttachment: {
          // view is acquired and set in render loop.
          view: undefined,

          depthClearValue: 1.0,
          depthLoadOp: 'clear',
          depthStoreOp: 'store',
          stencilLoadOp: 'load',
          stencilStoreOp: 'store',
        }
      };

      uniformBuffer = device.createBuffer({
        label: 'Uniform Buffer',
        size: uniformBufferSize,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
      });

      const sampler = device.createSampler({
        label: 'Default Sampler',
        minFilter: 'linear',
        magFilter: 'linear',
        mipmapFilter: 'linear',
      });

      function generateMipmap(gpuDevice, texture, textureDescriptor) {
        // Create a simple shader that renders a fullscreen textured quad.
        const mipmapShaderModule = gpuDevice.createShaderModule({
          label: 'Mipmap Shader',
          code: `
              var<private> pos : array<vec2<f32>, 4> = array<vec2<f32>, 4>(
                vec2<f32>(-1.0, 1.0), vec2<f32>(1.0, 1.0),
                vec2<f32>(-1.0, -1.0), vec2<f32>(1.0, -1.0));

              struct VertexOutput {
                @builtin(position) position : vec4<f32>,
                @location(0) texCoord : vec2<f32>,
              };

              @vertex
              fn vertexMain(@builtin(vertex_index) vertexIndex : u32) -> VertexOutput {
                var output : VertexOutput;
                output.texCoord = pos[vertexIndex] * vec2<f32>(0.5, -0.5) + vec2<f32>(0.5);
                output.position = vec4<f32>(pos[vertexIndex], 0.0, 1.0);
                return output;
              }

              @group(0) @binding(0) var imgSampler : sampler;
              @group(0) @binding(1) var img : texture_2d<f32>;

              @fragment
              fn fragmentMain(@location(0) texCoord : vec2<f32>) -> @location(0) vec4<f32> {
                return textureSample(img, imgSampler, texCoord);
              }
            `
        });

        const pipeline = gpuDevice.createRenderPipeline({
          layout: 'auto',
          vertex: {
            module: mipmapShaderModule,
            entryPoint: 'vertexMain',
          },
          fragment: {
            module: mipmapShaderModule,
            entryPoint: 'fragmentMain',
            targets: [{
              format: textureDescriptor.format // Make sure to use the same format as the texture
            }],
          },
          primitive: {
            topology: 'triangle-strip',
            stripIndexFormat: 'uint32',
          },
        });

        // We'll ALWAYS be rendering minified here, so that's the only filter mode we need to set.
        const sampler = gpuDevice.createSampler({
          minFilter: 'linear',
          magFilter: 'linear',
          mipmapFilter: 'linear',
        });

        let srcView = texture.createView({
          baseMipLevel: 0,
          mipLevelCount: 1
        });

        // Loop through each mip level and renders the previous level's contents into it.
        const commandEncoder = gpuDevice.createCommandEncoder({});
        for (let i = 1; i < textureDescriptor.mipLevelCount; ++i) {
          const dstView = texture.createView({
            baseMipLevel: i,  // Make sure we're getting the right mip level...
            mipLevelCount: 1, // And only selecting one mip level
          });

          const passEncoder = commandEncoder.beginRenderPass({
            colorAttachments: [{
              view: dstView, // Render pass uses the next mip level as it's render attachment.
              loadOp: 'clear',
              storeOp: 'store'
            }],
          });

          // Need a separate bind group for each level to ensure
          // we're only sampling from the previous level.
          const bindGroup = gpuDevice.createBindGroup({
            layout: pipeline.getBindGroupLayout(0),
            entries: [{
              binding: 0,
              resource: sampler,
            }, {
              binding: 1,
              resource: srcView,
            }],
          });

          // Render
          passEncoder.setPipeline(pipeline);
          passEncoder.setBindGroup(0, bindGroup);
          passEncoder.draw(4);
          passEncoder.end();

          // The source texture view for the next iteration of the loop is the
          // destination view for this one.
          srcView = dstView;
        }
        gpuDevice.queue.submit([commandEncoder.finish()]);
      }

      async function textureFromImageUrl(gpuDevice, url) {
        const response = await fetch(url);
        const blob = await response.blob();
        const source = await createImageBitmap(blob);

        const textureDescriptor = {
          label: `${url} Texture`,
          size: { width: source.width, height: source.height },
          format: 'rgba8unorm',
          mipLevelCount: Math.floor(Math.log2(Math.max(source.width, source.height))) + 1,
          usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST
        };

        const texture = gpuDevice.createTexture(textureDescriptor);

        gpuDevice.queue.copyExternalImageToTexture({ source }, { texture }, textureDescriptor.size);

        generateMipmap(gpuDevice, texture, textureDescriptor);

        return texture;
      }

      textureFromImageUrl(device, 'logo.png').then((texture) => {
        uniformBindGroup = device.createBindGroup({
          label: 'Cube Bind Group',
          layout: pipeline.getBindGroupLayout(0),
          entries: [{
            binding: 0,
            resource: {
              buffer: uniformBuffer,
            },
          }, {
            binding: 1,
            resource: texture.createView(),
          }, {
            binding: 2,
            resource: sampler,
          }],
        });
      });

      function onResize() {
        context.configure({
          device,
          format: contextFormat,
          usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC,
          alphaMode: 'premultiplied'
        });

        if (sampleCount > 1) {
          colorTexture = device.createTexture({
            size: {
              width: canvas.width,
              height: canvas.height,
            },
            sampleCount,
            format: contextFormat,
            usage: GPUTextureUsage.RENDER_ATTACHMENT,
          });
          renderPassDescriptor.colorAttachments[0].view = colorTexture.createView();
        } else {
          renderPassDescriptor.colorAttachments[0].resolveTarget = undefined;
        }

        depthTexture = device.createTexture({
          size: {
            width: canvas.width,
            height: canvas.height,
          },
          sampleCount,
          format: depthFormat,
          usage: GPUTextureUsage.RENDER_ATTACHMENT
        });
        renderPassDescriptor.depthStencilAttachment.view = depthTexture.createView();

        const aspect = Math.abs(canvas.width / canvas.height);
        mat4.perspective(projectionMatrix, Math.PI * 0.5, aspect, 0.1, 5.0);
      }
      window.addEventListener('resize', onResize);
      onResize();

      window.requestAnimationFrame(onFrame);
    }

    function getTransformationMatrix() {
      mat4.identity(viewMatrix);
      mat4.translate(viewMatrix, viewMatrix, vec3.fromValues(0, 0, -3));
      let now = Date.now() / 1000;
      mat4.rotate(viewMatrix, viewMatrix, 1, vec3.fromValues(Math.sin(now), Math.cos(now), 0));

      mat4.multiply(modelViewProjectionMatrix, projectionMatrix, viewMatrix);

      return modelViewProjectionMatrix;
    }

    function onFrame() {
      device.queue.writeBuffer(uniformBuffer, 0, getTransformationMatrix());

      const commandEncoder = device.createCommandEncoder({});

      const swapTexture = context.getCurrentTexture();
      if (sampleCount > 1) {
        renderPassDescriptor.colorAttachments[0].resolveTarget = swapTexture.createView();
      } else {
        renderPassDescriptor.colorAttachments[0].view = swapTexture.createView();
      }
      const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);

      if (uniformBindGroup) {
        passEncoder.setPipeline(pipeline);
        passEncoder.setBindGroup(0, uniformBindGroup);
        passEncoder.setVertexBuffer(0, vertexBuffer);
        passEncoder.draw(Cube.vertexCount, 1, 0, 0);
      }

      passEncoder.end();

      device.queue.submit([commandEncoder.finish()]);

      window.requestAnimationFrame(onFrame);
    }

    initWebGPU();
  </script>
</body>

</html>